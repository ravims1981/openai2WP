{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l0gins = [\n",
    "    {'wpDomain':'yourdomain.com', \n",
    "     'wpUN':'admin', #The user needs to have admin privs\n",
    "     'wpPW':'slkdfjsldfjsldkjf', #Wordpress Application Password of an account with admin privs\n",
    "     'post_status':'draft', #or 'publish'\n",
    "     'kw':['pubic hairloss', 'greying armpit hair'],\n",
    "     'pexels_key':'lsdfjsdlfjslkdjflkdjf',\n",
    "     'openai_key':'skldfjslkdfjslkdfjjdf'\n",
    "     }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "!pip install torch transformers sentencepiece protobuf==3.20 openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO as bIO\n",
    "import openai, torch\n",
    "from json import loads as jLD, dumps as jD\n",
    "from requests import get as g, post as p\n",
    "from datetime import datetime as dT, timedelta as tD\n",
    "from PIL import Image as img, ImageEnhance as iE, ImageFilter as iF\n",
    "from secrets import token_hex as heX\n",
    "from base64 import b64encode as be\n",
    "from os import  path as pt, remove as rm\n",
    "from sys import exit as eX\n",
    "from time import perf_counter as pC, sleep as zZz\n",
    "from random import uniform as u, choice as c, randint as ri, randrange as rr\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiStart = pC()\n",
    "print('Instantiating the AI')\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"ramsrigouthamg/t5_sentence_paraphraser\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ramsrigouthamg/t5_sentence_paraphraser\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "print('AI instantiated in', pC()-aiStart)\n",
    "beams = sequences = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deDupeQ(my_list):\n",
    "  jpop=[]\n",
    "  for i in range(len(my_list)):\n",
    "    for j in range(i+1, len(my_list)):\n",
    "      if my_list[i] == my_list[j]:\n",
    "        jpop.append(j)\n",
    "  print(f'{len(jpop)} dupes found in qList')\n",
    "  for j in reversed(sorted(jpop)):\n",
    "    my_list.pop(j)\n",
    "  return my_list\n",
    "\n",
    "def imgJSON(kw, qLen):\n",
    "  totalimg = qLen * 4\n",
    "  imJson = g(\"https://api.pexels.com/v1/search\", params={\"query\": kw,\"per_page\": 80,\"page\": 1}, headers={\"Authorization\": f\"Bearer {pexels_api_key}\"}).json()\n",
    "  for page in range(round(totalimg/80)-1):\n",
    "    zZz(1)\n",
    "    imJson['photos'].extend(g(\"https://api.pexels.com/v1/search\", params={\"query\": kw,\"per_page\": 80,\"page\": page+2}, headers={\"Authorization\": f\"Bearer {pexels_api_key}\"}).json()['photos'])\n",
    "  dedup = deDupeQ(imJson['photos'])\n",
    "  imJson['photos'] = dedup\n",
    "  print(f\"Got {len(imJson['photos'])} images from pexels that had {len(imJson['photos'])-len(dedup)} dupes effectively leaving {len(dedup)} available for an estimated requirement of {totalimg} for this run\")\n",
    "  return imJson\n",
    "\n",
    "def randomDateTime(n, days=30, repeats=10, hours_diff=3):\n",
    "    # Define start and end dates\n",
    "    start_date = dT.now()\n",
    "    end_date = start_date + tD(days=days)\n",
    "\n",
    "    # Calculate time delta and maximum number of repetitions per date\n",
    "    delta_seconds = (end_date - start_date).total_seconds() / n\n",
    "    max_repeats = int(n / (days * repeats))\n",
    "\n",
    "    # Generate timestamps\n",
    "    timestamps = set()\n",
    "    current_date = start_date\n",
    "    count = 0\n",
    "    while len(timestamps) < n:\n",
    "        for i in range(repeats):\n",
    "            # Check if the maximum number of repetitions for the current date has been reached\n",
    "            if count >= max_repeats:\n",
    "                current_date += tD(days=1)\n",
    "                count = 0\n",
    "            # Generate a timestamp for the current date with a random time\n",
    "            rand_seconds = u(0, delta_seconds)\n",
    "            date = current_date + tD(seconds=rand_seconds)\n",
    "            timestamp = date.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "            while timestamp in timestamps:\n",
    "                # Regenerate the timestamp if it already exists in the set\n",
    "                rand_seconds = u(0, delta_seconds)\n",
    "                date = current_date + tD(seconds=rand_seconds)\n",
    "                timestamp = date.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "            timestamps.add(timestamp)\n",
    "            count += 1\n",
    "        # Move to the next date\n",
    "        current_date += tD(hours=hours_diff)\n",
    "\n",
    "    # Return the list of timestamps\n",
    "    return list(timestamps)\n",
    "\n",
    "def openAI(text):\n",
    "  retry = 0\n",
    "  t = 10\n",
    "  while True:\n",
    "    try:\n",
    "      return openai.Completion.create(model=\"text-davinci-003\", prompt=text, max_tokens=1000, temperature=0.7)['choices'][0]['text']  \n",
    "    except Exception as e:\n",
    "      retry +=1\n",
    "      print(f'OpenAI threw an error {e}, sleeping for {t} seconds. Retry {retry} of 5')\n",
    "      if retry == 5:\n",
    "        eX(f'Looks like openAI is fucked. See you on the otherside')\n",
    "      else:\n",
    "        zZz(t)\n",
    "        t += 10\n",
    "        continue\n",
    "\n",
    "def contentProcessor(text):\n",
    "    def paraPhraser(input_text):\n",
    "        text = \"paraphrase: \"+input_text + \" </s>\"\n",
    "        encoding = tokenizer.encode_plus(text,max_length =256, padding='max_length', return_tensors=\"pt\")\n",
    "        input_ids,attention_mask  = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
    "        model.eval()\n",
    "        beam_outputs = model.generate(\n",
    "            input_ids=input_ids,attention_mask=attention_mask,\n",
    "            max_length=256,\n",
    "            early_stopping=True,\n",
    "            num_beams=beams,\n",
    "            num_return_sequences=sequences\n",
    "        )\n",
    "        sendBack = []\n",
    "        for beam_output in beam_outputs:\n",
    "            sent = tokenizer.decode(beam_output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
    "            sendBack.append(str(sent).strip('paraphrasedoutput: '))\n",
    "        return sendBack\n",
    "    finalText = ''\n",
    "    print(f\"Processing \\n\\n{text}\\n\\nof {len(text.split())} words in text\\n\\n\\n\")\n",
    "    cPTimer = pC()\n",
    "    paraSplit = list(filter(lambda x: x != '', text.split('\\n\\n')))\n",
    "    paraLength = len(paraSplit)\n",
    "    for para in paraSplit:\n",
    "        phrases = para.split('. ')\n",
    "        phraseLength = len(phrases)\n",
    "        for phrase in phrases:\n",
    "            rphResponse = paraPhraser(input_text=phrase)\n",
    "            finalText += c(rphResponse)\n",
    "            if phraseLength > 1:\n",
    "                finalText += ' '\n",
    "        if paraLength > 1:\n",
    "            finalText += '\\n\\n'\n",
    "    print(f\"Processed Text \\n\\n{finalText}\\n\\n of {len(finalText.split())} words processed in {round(pC()-cPTimer)} seconds\\n\\n\\n\")\n",
    "    return finalText\n",
    "\n",
    "def imgAdder(text, dicT, imJSON):\n",
    "  def imgPost(data):\n",
    "    headers = {\"Content-Type\": \"image/jpeg\", \"Accept\": \"application/json\", 'Content-Disposition': f\"attachment; filename={heX(20)}.jpg\",}\n",
    "    auth = (dicT['wpUN'], dicT['wpPW'])\n",
    "    return p(url = f'https://{dicT[\"wpDomain\"]}/wp-json/wp/v2/media', auth=auth, headers=headers, data=data).json()  \n",
    "  def imgFuckery(data):\n",
    "    image = img.open(bIO(data))    \n",
    "    enhancer = iE.Color(image)\n",
    "    fI = enhancer.enhance(u(.6,.9))\n",
    "    fI = fI.filter(iF.BoxBlur(radius=u(0.5,2.5)))\n",
    "    fI = fI.filter(iF.SMOOTH)\n",
    "    fI = fI.filter(iF.EDGE_ENHANCE)\n",
    "    fI = fI.filter(iF.SHARPEN)\n",
    "    fI = fI.filter(iF.DETAIL)\n",
    "    if c([0,1]) == 1:\n",
    "      fI = fI.rotate(u(-.7,.7))\n",
    "    if c([0,1]) == 1:\n",
    "      fI = fI.transpose(img.FLIP_LEFT_RIGHT)\n",
    "    imgData = bIO()\n",
    "    fI.save(imgData, format='JPEG')\n",
    "    return imgData.getvalue()\n",
    "  def imgFetch():   \n",
    "    imgList = []\n",
    "    randomimgn = []\n",
    "    for i in range(imgN):\n",
    "      while True:\n",
    "        rn = ri(0, len(imJSON['photos'])-1)\n",
    "        if rn not in randomimgn:\n",
    "          randomimgn.append(rn)\n",
    "          break\n",
    "    aDDed = []\n",
    "    for _ in range(len(randomimgn)):\n",
    "      while True:\n",
    "        i = ri(0, len(imJSON['photos'])-1)\n",
    "        if i in aDDed:\n",
    "          continue\n",
    "        else:\n",
    "          aDDed.append(i)\n",
    "          if 'large' in imJSON['photos'][i]['src']:\n",
    "            imgSize = 'large'\n",
    "            break\n",
    "          elif 'medium' in imJSON['photos'][i]['src']:\n",
    "            imgSize = 'medium'\n",
    "            break\n",
    "          elif 'small' in imJSON['photos'][i]['src']:\n",
    "            imgSize = 'small'\n",
    "            break\n",
    "          else:\n",
    "            continue      \n",
    "      imgList.append(imgPost(data=imgFuckery(g(imJSON['photos'][i]['src'][imgSize]).content))['guid']['raw'])\n",
    "      print(f\"Making list of images. Length of imglist now is {len(imgList)}\")\n",
    "    print('And BOOM! thats done')\n",
    "    return imgList\n",
    "  paras = list(filter(lambda x: x != '', text.split('\\n\\n')))\n",
    "  paralen = len(paras)\n",
    "  print('paralength',paralen)\n",
    "  imgN = ri(2, round(paralen/2)) if paralen > 3 else 1\n",
    "  print('imgn',imgN)\n",
    "  imgInterval = []\n",
    "  if imgN == 1 and paralen == 2:\n",
    "    imgInterval.append(1)\n",
    "  elif imgN == 1 and paralen == 1:\n",
    "    imgInterval.append(0)\n",
    "  else:\n",
    "    for i in range(imgN):\n",
    "      reTRy = 0\n",
    "      while True: \n",
    "        rnrint = ri(0,paralen-2)\n",
    "        if rnrint not in imgInterval:\n",
    "          imgInterval.append(rnrint)\n",
    "          break\n",
    "        reTRy += 1\n",
    "        if reTRy > 100:\n",
    "          break\n",
    "  print('imgInterval',imgInterval)\n",
    "  imglist = imgFetch()\n",
    "  print('imglist length',len(imglist))\n",
    "  imglistn = 0\n",
    "  article = ''\n",
    "  for i, para in enumerate(paras):\n",
    "    article += f'{para}\\n\\n'\n",
    "    if i in imgInterval and imglistn <= len(imglist)-1:\n",
    "        if i==0:\n",
    "          article = f'<img src=\"{imglist[imglistn]}\" /> \\n\\n  {article}'\n",
    "        else:\n",
    "          article += f'<img src=\"{imglist[imglistn]}\" /> \\n\\n'\n",
    "        imglistn += 1\n",
    "  return article  \n",
    "\n",
    "def qListWrite(jSON):\n",
    "  with open('/content/qlist.json','w') as qListWriter:\n",
    "    qListWriter.write(jD(jSON))\n",
    "\n",
    "def qListReader():\n",
    "  if not pt.exists('/content/qlist.json'):\n",
    "    qListWrite({})\n",
    "    qListJson = {}\n",
    "  else:\n",
    "    try:\n",
    "      with open('/content/qlist.json','r') as qListReader:\n",
    "        qListJson = jLD(qListReader.read())\n",
    "    except:\n",
    "      qListWrite({})\n",
    "      qListJson = {}\n",
    "    else:\n",
    "      return qListJson\n",
    "\n",
    "  return qListJson\n",
    "\n",
    "def qListMaker(kw):\n",
    "  topicsList = openAI(f\"give me a list topics around {kw} as a comma separated list without any serial numbers\").replace(\"\\n\",'').split(',')\n",
    "  for i, t in enumerate(topicsList):\n",
    "    print(f'{i+1}. {t.strip()} in {kw}')\n",
    "  qList = []\n",
    "  for topic in topicsList:\n",
    "    print('Pulling questions for', topic)\n",
    "    zZz(2)\n",
    "    qList.extend(openAI(f\"a list questions around the topic {f'{topic.strip()} in {kw}'} as a comma separated list without serial numbers\").replace(\"\\n\",'').split(','))\n",
    "  qLIST = []\n",
    "  qlen = len(qList)\n",
    "  conversionsTart = pC()\n",
    "  for i, q in enumerate(qList):\n",
    "    q = ''.join([s.strip('\\\"') for s in q]).strip()\n",
    "    print(f\"Converting {i} of {qlen}, Title: {q.strip()} to a blog title. Time elapsed : {pC()-conversionsTart}\")\n",
    "    qLIST.append(''.join([s.strip('\\\"') for s in contentProcessor(openAI(f'''convert this question {q} to a blog post title''').replace(\"\\n\",'').strip())]))\n",
    "    print(f\"Original question: {q}\\nProcessed Output{qLIST[i]}\\n\\n\")\n",
    "  qList = qListJson[kw]=deDupeQ(qLIST)\n",
    "  qListWrite(jSON=qListJson)\n",
    "  for i, q in enumerate(qList):\n",
    "    print(i+1, q)\n",
    "  qListJson[kw]=deDupeQ(qList)\n",
    "  qListWrite(jSON=qListJson)\n",
    "  return qList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dicT in enumerate(l0gins):\n",
    "  openai.api_key = dicT['openai_key']\n",
    "  pexels_api_key = dicT['pexels_key']\n",
    "  print('\\n\\nProceeding with', dicT['wpDomain'])\n",
    "  wpHeaders = {'Authorization':'Basic '+be(f\"{dicT['wpUN']}:{dicT['wpPW']}\".encode()).decode()}\n",
    "  wpPostsURL = f\"https://{dicT['wpDomain']}/wp-json/wp/v2/posts\"\n",
    "  wpStatus = dicT['post_status']\n",
    "  for j, kw in enumerate(dicT['kw']):\n",
    "    qListJson = qListReader()\n",
    "    if kw in qListJson:\n",
    "      print('Found kw in qlist.json')\n",
    "      qList = deDupeQ(qListJson[kw])\n",
    "      if len(qList) == 0:\n",
    "        print('qList is as empty as your fucking brain, pulling qs from openai')\n",
    "        qList = qListMaker(kw)\n",
    "      print(f'Got back {len(qList)} questions')\n",
    "    else:\n",
    "      print(f'Kw not found in qlist.json, this probably means this is the first time you are running this keyword. pulling questions from openai')\n",
    "      qList = qListMaker(kw=kw)\n",
    "      print(f'Got back {len(qList)} questions')\n",
    "    qListOriginalLength = len(qList)\n",
    "    sTart = pC()\n",
    "    imJSON = imgJSON(kw=kw, qLen= qListOriginalLength)\n",
    "    datelist = randomDateTime(n=qListOriginalLength)\n",
    "    while True:\n",
    "      if len(qList) == 0:\n",
    "        print(f\"{qListOriginalLength} posts done in {(pC()-sTart)/60} minutes\")\n",
    "        del qListJson[kw]\n",
    "        qListWrite(jSON=qListJson)\n",
    "        break\n",
    "      title = c(qList)\n",
    "      print(f\"\\n\\n\\nFor title '{title}', IMJson length is {len(imJSON['photos'])}, {qListOriginalLength - len(qList)+1} of {qListOriginalLength}. Time Elapsed: {round(pC()-sTart)/60} minutes\")\n",
    "      postStart = pC()\n",
    "      print(f\"{title} Posted to to {dicT['wpDomain']}\\n{qListOriginalLength - (len(qList)-1)} of {qListOriginalLength} questions Posted.\\n{j+1} of {len(dicT['kw'])} keywords\\n{len(l0gins)-(i+1)} of {len(l0gins)} domains done. \\nPost response {p(url=wpPostsURL, headers=wpHeaders, json={'title':title,'status':wpStatus, 'date_gmt':datelist.pop(rr(len(datelist))), 'content':imgAdder(text=contentProcessor(openAI(f'a detailed essay on {title}')), dicT=dicT, imJSON=imJSON)})}\\nDone in {postStart-pC()} seconds\\nRemaining {len(qList)-1}\")\n",
    "      qList.remove(title)\n",
    "      qListJson[kw]=qList\n",
    "      qListWrite(jSON=qListJson)\n",
    "      print('Next one in 3 secs')\n",
    "      zZz(3)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
